{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "489mxdvFSWkC"
      },
      "outputs": [],
      "source": [
        "\n",
        "#newIndex=[[keyword ,[url1,url2,...,],# of links], [keyword2 ,[url2,url3,...,],# of links]]\n",
        "\n",
        "def union(list1, list2):\n",
        "  for element in list2:\n",
        "    if element not in list1:\n",
        "      list1.append(element)\n",
        "  return list1\n",
        "\n",
        "def addToIndex(index,keyword,url): #This procedure is adjusted to the new type of index.\n",
        "  presentKeyword = False #To search for each keyword in the index structure, this boolean is assigned.\n",
        "  for cell in index:\n",
        "    if cell[0] == keyword:\n",
        "      union(cell[1],[url])\n",
        "      cell[2] = len(cell[1])\n",
        "      presentKeyword=True\n",
        "  if not presentKeyword:\n",
        "    index.append([keyword, [url], 1])\n",
        "  return index\n",
        "\n",
        "def getPage(url):\n",
        "  try:\n",
        "    import urllib.request\n",
        "    page = urllib.request.urlopen(url).read()\n",
        "    page = page.decode(\"utf-8\")\n",
        "    return page\n",
        "  except:\n",
        "    return \"\"\n",
        "\n",
        "def addPageToIndex(index, url,content):\n",
        "  contentList=content.split()\n",
        "  for element in contentList:\n",
        "    addToIndex(index,element,url)\n",
        "  return index\n",
        "\n",
        "def getNextTarget(page):\n",
        "  startLink=page.find('<a href=')\n",
        "  if startLink==-1:\n",
        "    return None,0\n",
        "  startQuote = page.find('\"', startLink+1)\n",
        "  endQuote= page.find('\"', startQuote+1 )\n",
        "  url= page[startQuote+1: endQuote]\n",
        "  return url, endQuote\n",
        "\n",
        "def getAllLinks(page):\n",
        "  urlList=[]\n",
        "  while True:\n",
        "    myUrl, lastQuote = getNextTarget(page)\n",
        "    if myUrl:\n",
        "      page=page[lastQuote:]\n",
        "      urlList.append(myUrl)\n",
        "    else:\n",
        "      break\n",
        "  return urlList\n",
        "\n",
        "def crawlWeb(seed):\n",
        "  tocrawl=[seed]\n",
        "  crawled=[]\n",
        "  index=[]\n",
        "  graph={}\n",
        "  while tocrawl:\n",
        "    page=tocrawl.pop()\n",
        "    if page not in crawled:\n",
        "      content=getPage(page)\n",
        "      addPageToIndex(index,page,content)\n",
        "      graph[page]=getAllLinks(page)\n",
        "      union(tocrawl,getAllLinks(getPage(page)))\n",
        "      crawled.append(page)\n",
        "  return index,graph\n",
        "\n",
        "index, graph = crawlWeb(\"https://searchengineplaces.com.tr/\") #Assignment of index and graph to the output of crawlWeb\n",
        "\n",
        "def computeRanks (graph) :\n",
        "  d = 0.8 # damping factor\n",
        "  N = len( graph ) # number of pages\n",
        "  numloops = 10 # effects the accuracy\n",
        "  ranks = {}\n",
        "  for page in graph :\n",
        "    ranks [ page ] = 1/ N\n",
        "\n",
        "  for i in range (0 , numloops ) :\n",
        "    newranks = {}\n",
        "    for page in graph :\n",
        "      newrank = (1-d ) / N\n",
        "      for node in graph :\n",
        "        if page in graph [ node ]:\n",
        "          newrank = newrank + d*(ranks[node]/len(graph(node)))\n",
        "      newranks [ page ] = newrank\n",
        "    ranks = newranks\n",
        "  return newranks\n",
        "\n",
        "ranks = computeRanks(graph) #Assignment of the ranks to the output of computeRanks\n",
        "\n",
        "def lookUpPageRank(index,keyword,ranks): #With this fuction, the related urls of the given keyword is found.\n",
        "  readytoSort={}\n",
        "  numberOfLinks = 0\n",
        "  keywords=[cell[0] for cell in index] #All keywords are assigned to a list\n",
        "  if keyword not in keywords:\n",
        "    return \"No result found.\"\n",
        "  if keyword in keywords:\n",
        "     for cell in index:\n",
        "      if keyword==cell[0]:\n",
        "        unsortedList = cell[1]\n",
        "        numberOfLinks = len(cell[1])\n",
        "        for links in unsortedList:\n",
        "         readytoSort[links]=ranks[links]\n",
        "\n",
        "  sortedList = sorted(readytoSort, key=readytoSort.get, reverse=True)\n",
        "  print(f'Keyword: {keyword}')\n",
        "  print(f'{numberOfLinks} result(s) found.')\n",
        "  print('Urls: ')\n",
        "  for url in sortedList:\n",
        "      print(url)\n",
        "\n",
        "def lookupLink(index, url): #With this function, the related keywords of the given url is found.\n",
        "  keywordsOfLinks = []\n",
        "  allLinks=[]\n",
        "  for cell in index:\n",
        "    allLinks= union(allLinks,cell[1])\n",
        "\n",
        "  if url in allLinks:\n",
        "    for cell in index:\n",
        "      if url in cell[1]:\n",
        "        keywordsOfLinks = union(keywordsOfLinks,[cell[0]])\n",
        "    print(f\"Link:  {url}\")\n",
        "    print(f'{len(keywordsOfLinks)} keyword(s) found.')\n",
        "\n",
        "    for element in keywordsOfLinks:\n",
        "      print(element)\n",
        "  else:\n",
        "    return \"No result found.\"\n",
        "\n",
        "lookUpPageRank(index,\"<!DOCTYPE\",ranks)\n",
        "\n",
        "lookupLink(index, \"http://www.searchengineplaces.com.tr/oktayrecommends.html\")"
      ]
    }
  ]
}